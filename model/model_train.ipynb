{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/meina/Github/meina-t/matching_with_dl'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_root = os.path.abspath('')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "logger = getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sv \n",
    "https://arxiv.org/pdf/2107.03427\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import MatchingNet, train_model\n",
    "from model.params import HParams\n",
    "from model.data import Data\n",
    "from model.loss.strategy_proofness import compute_spv\n",
    "from model.loss.stability import compute_sv\n",
    "from model.loss.efficiency import generate_stable_matchings, filter_efficient_stable_matchings, compute_ev\n",
    "from model.utils import is_pareto_dominates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = HParams(\n",
    "    num_agents=3,\n",
    "    num_hidden_nodes=64,\n",
    "    batch_size=128,\n",
    "    epochs=2000,\n",
    "    corr = 0,\n",
    "    device='mps',\n",
    "    lr=0.01,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatchingNet(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Epoch: 10\n",
      "Total Loss: 4.965608596801758\n",
      "SPV: 0.0035193879157304764\n",
      "SV: 0.658410906791687\n",
      "Objective Loss(ev): 0.3297705352306366\n",
      "Paramiters: lambda_spv = 1.1498084566555917, lambda_sv = 7.693232774734497, rho = 1\n",
      "---------------------------\n",
      "Epoch: 20\n",
      "Total Loss: 9.773368835449219\n",
      "SPV: 0.0036173106636852026\n",
      "SV: 0.6685671806335449\n",
      "Objective Loss(ev): 0.6563866138458252\n",
      "Paramiters: lambda_spv = 1.1780450765509158, lambda_sv = 14.298810422420502, rho = 1\n",
      "---------------------------\n",
      "Epoch: 30\n",
      "Total Loss: 14.03762149810791\n",
      "SPV: 0.034768588840961456\n",
      "SV: 0.6532100439071655\n",
      "Objective Loss(ev): 0.8628828525543213\n",
      "Paramiters: lambda_spv = 1.335722693009302, lambda_sv = 20.753185093402863, rho = 1\n",
      "---------------------------\n",
      "Epoch: 40\n",
      "Total Loss: 14.388965606689453\n",
      "SPV: 0.46244657039642334\n",
      "SV: 0.47323372960090637\n",
      "Objective Loss(ev): 0.4681311845779419\n",
      "Paramiters: lambda_spv = 4.01011608238332, lambda_sv = 26.42283606529236, rho = 1\n",
      "---------------------------\n",
      "Epoch: 50\n",
      "Total Loss: 15.116349220275879\n",
      "SPV: 0.2953639328479767\n",
      "SV: 0.40628582239151\n",
      "Objective Loss(ev): 0.4943464398384094\n",
      "Paramiters: lambda_spv = 8.297521185828373, lambda_sv = 30.57828038930893, rho = 1\n",
      "---------------------------\n",
      "Epoch: 60\n",
      "Total Loss: 18.006370544433594\n",
      "SPV: 0.2322484850883484\n",
      "SV: 0.4310373067855835\n",
      "Objective Loss(ev): 0.695857048034668\n",
      "Paramiters: lambda_spv = 11.407935050083324, lambda_sv = 34.56955897808075, rho = 1\n",
      "---------------------------\n",
      "Epoch: 70\n",
      "Total Loss: 13.504110336303711\n",
      "SPV: 0.20792070031166077\n",
      "SV: 0.27532491087913513\n",
      "Objective Loss(ev): 0.42616161704063416\n",
      "Paramiters: lambda_spv = 13.430063125444576, lambda_sv = 37.79024538397789, rho = 1\n",
      "---------------------------\n",
      "Epoch: 80\n",
      "Total Loss: 15.482930183410645\n",
      "SPV: 0.10501788556575775\n",
      "SV: 0.3301710784435272\n",
      "Objective Loss(ev): 0.5784519910812378\n",
      "Paramiters: lambda_spv = 14.804489542497322, lambda_sv = 40.79637813568115, rho = 1\n",
      "---------------------------\n",
      "Epoch: 90\n",
      "Total Loss: 11.03446102142334\n",
      "SPV: 0.1100044846534729\n",
      "SV: 0.2088964581489563\n",
      "Objective Loss(ev): 0.37706515192985535\n",
      "Paramiters: lambda_spv = 15.871801231754944, lambda_sv = 42.92636360228062, rho = 1\n",
      "---------------------------\n",
      "Epoch: 100\n",
      "Total Loss: 7.0849409103393555\n",
      "SPV: 0.09475169330835342\n",
      "SV: 0.11626936495304108\n",
      "Objective Loss(ev): 0.34191226959228516\n",
      "Paramiters: lambda_spv = 16.796741996658966, lambda_sv = 44.50015950202942, rho = 1\n",
      "---------------------------\n",
      "Epoch: 110\n",
      "Total Loss: 8.398744583129883\n",
      "SPV: 0.056153520941734314\n",
      "SV: 0.15449370443820953\n",
      "Objective Loss(ev): 0.3617171347141266\n",
      "Paramiters: lambda_spv = 17.487800867063925, lambda_sv = 45.840366676449776, rho = 1\n",
      "---------------------------\n",
      "Epoch: 120\n",
      "Total Loss: 6.40103006362915\n",
      "SPV: 0.028228115290403366\n",
      "SV: 0.11785002052783966\n",
      "Objective Loss(ev): 0.3697289228439331\n",
      "Paramiters: lambda_spv = 18.084833149565384, lambda_sv = 46.97059939056635, rho = 1\n",
      "---------------------------\n",
      "Epoch: 130\n",
      "Total Loss: 7.81500244140625\n",
      "SPV: 0.05815671384334564\n",
      "SV: 0.13469940423965454\n",
      "Objective Loss(ev): 0.26670825481414795\n",
      "Paramiters: lambda_spv = 18.478949106065556, lambda_sv = 48.219555608928204, rho = 1\n",
      "---------------------------\n",
      "Epoch: 140\n",
      "Total Loss: 6.742835998535156\n",
      "SPV: 0.05536207929253578\n",
      "SV: 0.1083010584115982\n",
      "Objective Loss(ev): 0.34647276997566223\n",
      "Paramiters: lambda_spv = 18.90108160371892, lambda_sv = 49.535563327372074, rho = 1\n",
      "---------------------------\n",
      "Epoch: 150\n",
      "Total Loss: 6.668404579162598\n",
      "SPV: 0.05078943073749542\n",
      "SV: 0.10538304597139359\n",
      "Objective Loss(ev): 0.3671365976333618\n",
      "Paramiters: lambda_spv = 19.3706729139667, lambda_sv = 50.58810029178858, rho = 1\n",
      "---------------------------\n",
      "Epoch: 160\n",
      "Total Loss: 9.189197540283203\n",
      "SPV: 0.077930748462677\n",
      "SV: 0.1441698968410492\n",
      "Objective Loss(ev): 0.22672994434833527\n",
      "Paramiters: lambda_spv = 19.694279614603147, lambda_sv = 51.706604450941086, rho = 1\n",
      "---------------------------\n",
      "Epoch: 170\n",
      "Total Loss: 3.573612928390503\n",
      "SPV: 0.03794069588184357\n",
      "SV: 0.05014171823859215\n",
      "Objective Loss(ev): 0.17274269461631775\n",
      "Paramiters: lambda_spv = 20.105458142003044, lambda_sv = 52.69083518907428, rho = 1\n",
      "---------------------------\n",
      "Epoch: 180\n",
      "Total Loss: 5.811162948608398\n",
      "SPV: 0.045578595250844955\n",
      "SV: 0.08592334389686584\n",
      "Objective Loss(ev): 0.26783573627471924\n",
      "Paramiters: lambda_spv = 20.48091606865637, lambda_sv = 53.760662373155355, rho = 1\n",
      "---------------------------\n",
      "Epoch: 190\n",
      "Total Loss: 6.7602949142456055\n",
      "SPV: 0.033512894064188004\n",
      "SV: 0.1078471690416336\n",
      "Objective Loss(ev): 0.17473912239074707\n",
      "Paramiters: lambda_spv = 20.71033460344188, lambda_sv = 54.746425438672304, rho = 1\n",
      "---------------------------\n",
      "Epoch: 200\n",
      "Total Loss: 6.224852561950684\n",
      "SPV: 0.03983904793858528\n",
      "SV: 0.09451387077569962\n",
      "Objective Loss(ev): 0.14200183749198914\n",
      "Paramiters: lambda_spv = 20.983247604919598, lambda_sv = 55.62589117512107, rho = 1\n",
      "---------------------------\n",
      "Epoch: 210\n",
      "Total Loss: 4.3411760330200195\n",
      "SPV: 0.029641563072800636\n",
      "SV: 0.062338437885046005\n",
      "Objective Loss(ev): 0.184395894408226\n",
      "Paramiters: lambda_spv = 21.360039845807478, lambda_sv = 56.60071009397507, rho = 1\n",
      "---------------------------\n",
      "Epoch: 220\n",
      "Total Loss: 7.304169654846191\n",
      "SPV: 0.03905930370092392\n",
      "SV: 0.11047802120447159\n",
      "Objective Loss(ev): 0.11920109391212463\n",
      "Paramiters: lambda_spv = 21.79011157597415, lambda_sv = 57.45570310205221, rho = 1\n",
      "---------------------------\n",
      "Epoch: 230\n",
      "Total Loss: 5.783951759338379\n",
      "SPV: 0.045995842665433884\n",
      "SV: 0.07841906696557999\n",
      "Objective Loss(ev): 0.19177258014678955\n",
      "Paramiters: lambda_spv = 22.345168807310984, lambda_sv = 58.31054937839508, rho = 1\n",
      "---------------------------\n",
      "Epoch: 240\n",
      "Total Loss: 4.667325496673584\n",
      "SPV: 0.021572422236204147\n",
      "SV: 0.06786718219518661\n",
      "Objective Loss(ev): 0.16891519725322723\n",
      "Paramiters: lambda_spv = 22.707107142312452, lambda_sv = 59.1395406126976, rho = 1\n",
      "---------------------------\n",
      "Epoch: 250\n",
      "Total Loss: 4.1566996574401855\n",
      "SPV: 0.05009123310446739\n",
      "SV: 0.04775919020175934\n",
      "Objective Loss(ev): 0.1482209861278534\n",
      "Paramiters: lambda_spv = 23.04250591690652, lambda_sv = 59.86368502303958, rho = 1\n",
      "---------------------------\n",
      "Epoch: 260\n",
      "Total Loss: 5.893568992614746\n",
      "SPV: 0.021906591951847076\n",
      "SV: 0.08425852656364441\n",
      "Objective Loss(ev): 0.281867116689682\n",
      "Paramiters: lambda_spv = 23.328999436227605, lambda_sv = 60.625587444752455, rho = 1\n",
      "---------------------------\n",
      "Epoch: 270\n",
      "Total Loss: 5.916702747344971\n",
      "SPV: 0.03595246747136116\n",
      "SV: 0.07936421036720276\n",
      "Objective Loss(ev): 0.20548319816589355\n",
      "Paramiters: lambda_spv = 23.69732681266032, lambda_sv = 61.322767186909914, rho = 1\n",
      "---------------------------\n",
      "Epoch: 280\n",
      "Total Loss: 8.570383071899414\n",
      "SPV: 0.0772341713309288\n",
      "SV: 0.10518842935562134\n",
      "Objective Loss(ev): 0.10988643020391464\n",
      "Paramiters: lambda_spv = 24.749869648134336, lambda_sv = 62.421225529164076, rho = 1\n",
      "---------------------------\n",
      "Epoch: 290\n",
      "Total Loss: 9.23359203338623\n",
      "SPV: 0.08434871584177017\n",
      "SV: 0.11046582460403442\n",
      "Objective Loss(ev): 0.11368376016616821\n",
      "Paramiters: lambda_spv = 25.346435172250494, lambda_sv = 63.37965454533696, rho = 1\n",
      "---------------------------\n",
      "Epoch: 300\n",
      "Total Loss: 6.570999622344971\n",
      "SPV: 0.07625506818294525\n",
      "SV: 0.0701616108417511\n",
      "Objective Loss(ev): 0.10724720358848572\n",
      "Paramiters: lambda_spv = 25.745769936358556, lambda_sv = 64.29790058359504, rho = 1\n",
      "---------------------------\n",
      "Epoch: 310\n",
      "Total Loss: 4.616843223571777\n",
      "SPV: 0.019592545926570892\n",
      "SV: 0.06134842708706856\n",
      "Objective Loss(ev): 0.11960513144731522\n",
      "Paramiters: lambda_spv = 26.157972309505567, lambda_sv = 65.02015827223659, rho = 1\n",
      "---------------------------\n",
      "Epoch: 320\n",
      "Total Loss: 6.63383674621582\n",
      "SPV: 0.06741033494472504\n",
      "SV: 0.07194184511899948\n",
      "Objective Loss(ev): 0.12913104891777039\n",
      "Paramiters: lambda_spv = 26.486717818072066, lambda_sv = 65.73290421441197, rho = 1\n",
      "---------------------------\n",
      "Epoch: 330\n",
      "Total Loss: 5.627980709075928\n",
      "SPV: 0.030431460589170456\n",
      "SV: 0.07070335745811462\n",
      "Objective Loss(ev): 0.11897938698530197\n",
      "Paramiters: lambda_spv = 26.89752667187713, lambda_sv = 66.42394031956792, rho = 1\n",
      "---------------------------\n",
      "Epoch: 340\n",
      "Total Loss: 4.169607162475586\n",
      "SPV: 0.014398918487131596\n",
      "SV: 0.054299697279930115\n",
      "Objective Loss(ev): 0.13627341389656067\n",
      "Paramiters: lambda_spv = 27.199242634465918, lambda_sv = 67.12468335032463, rho = 1\n",
      "---------------------------\n",
      "Epoch: 350\n",
      "Total Loss: 6.406970024108887\n",
      "SPV: 0.024090392515063286\n",
      "SV: 0.08253417909145355\n",
      "Objective Loss(ev): 0.15803936123847961\n",
      "Paramiters: lambda_spv = 27.50507303304039, lambda_sv = 67.77452748641372, rho = 1\n",
      "---------------------------\n",
      "Epoch: 360\n",
      "Total Loss: 4.784556865692139\n",
      "SPV: 0.019993646070361137\n",
      "SV: 0.060624487698078156\n",
      "Objective Loss(ev): 0.07959272712469101\n",
      "Paramiters: lambda_spv = 27.783328901277855, lambda_sv = 68.51273665204644, rho = 1\n",
      "---------------------------\n",
      "Epoch: 370\n",
      "Total Loss: 5.606497764587402\n",
      "SPV: 0.02347378060221672\n",
      "SV: 0.06959430128335953\n",
      "Objective Loss(ev): 0.14355680346488953\n",
      "Paramiters: lambda_spv = 28.03752508130856, lambda_sv = 69.11756730079651, rho = 1\n",
      "---------------------------\n",
      "Epoch: 380\n",
      "Total Loss: 5.732257843017578\n",
      "SPV: 0.021578488871455193\n",
      "SV: 0.0721956193447113\n",
      "Objective Loss(ev): 0.08234424889087677\n",
      "Paramiters: lambda_spv = 28.349002852337435, lambda_sv = 69.86383355408907, rho = 1\n",
      "---------------------------\n",
      "Epoch: 390\n",
      "Total Loss: 6.918896198272705\n",
      "SPV: 0.02167128585278988\n",
      "SV: 0.08716882765293121\n",
      "Objective Loss(ev): 0.16040626168251038\n",
      "Paramiters: lambda_spv = 28.761890040012076, lambda_sv = 70.47531141899526, rho = 1\n",
      "---------------------------\n",
      "Epoch: 400\n",
      "Total Loss: 8.490766525268555\n",
      "SPV: 0.04199548065662384\n",
      "SV: 0.10096044838428497\n",
      "Objective Loss(ev): 0.08328596502542496\n",
      "Paramiters: lambda_spv = 29.032323624240234, lambda_sv = 71.31714367680252, rho = 1\n",
      "---------------------------\n",
      "Epoch: 410\n",
      "Total Loss: 3.4387266635894775\n",
      "SPV: 0.013530068099498749\n",
      "SV: 0.04055536538362503\n",
      "Objective Loss(ev): 0.12806424498558044\n",
      "Paramiters: lambda_spv = 29.323724692920223, lambda_sv = 71.89525245688856, rho = 1\n",
      "---------------------------\n",
      "Epoch: 420\n",
      "Total Loss: 6.716552257537842\n",
      "SPV: 0.043005023151636124\n",
      "SV: 0.07426765561103821\n",
      "Objective Loss(ev): 0.06468267738819122\n",
      "Paramiters: lambda_spv = 29.692322074668482, lambda_sv = 72.47186454199255, rho = 1\n",
      "---------------------------\n",
      "Epoch: 430\n",
      "Total Loss: 3.8628010749816895\n",
      "SPV: 0.02465236373245716\n",
      "SV: 0.04206574708223343\n",
      "Objective Loss(ev): 0.051538802683353424\n",
      "Paramiters: lambda_spv = 29.997785227606073, lambda_sv = 73.07901231758296, rho = 1\n",
      "---------------------------\n",
      "Epoch: 440\n",
      "Total Loss: 5.347087860107422\n",
      "SPV: 0.020920226350426674\n",
      "SV: 0.06260073184967041\n",
      "Objective Loss(ev): 0.10265494138002396\n",
      "Paramiters: lambda_spv = 30.365880232537165, lambda_sv = 73.69766825251281, rho = 1\n",
      "---------------------------\n",
      "Epoch: 450\n",
      "Total Loss: 5.695283889770508\n",
      "SPV: 0.0766984075307846\n",
      "SV: 0.044088684022426605\n",
      "Objective Loss(ev): 0.07024507224559784\n",
      "Paramiters: lambda_spv = 30.791990766534582, lambda_sv = 74.19519526325166, rho = 1\n",
      "---------------------------\n",
      "Epoch: 460\n",
      "Total Loss: 5.298666477203369\n",
      "SPV: 0.013827968388795853\n",
      "SV: 0.06348410993814468\n",
      "Objective Loss(ev): 0.12514393031597137\n",
      "Paramiters: lambda_spv = 31.095338175306097, lambda_sv = 74.78656699694693, rho = 1\n",
      "---------------------------\n",
      "Epoch: 470\n",
      "Total Loss: 5.019933223724365\n",
      "SPV: 0.03333592787384987\n",
      "SV: 0.051270321011543274\n",
      "Objective Loss(ev): 0.11276710033416748\n",
      "Paramiters: lambda_spv = 31.44231143523939, lambda_sv = 75.34081501699984, rho = 1\n",
      "---------------------------\n",
      "Epoch: 480\n",
      "Total Loss: 3.214376926422119\n",
      "SPV: 0.01072250958532095\n",
      "SV: 0.03633680194616318\n",
      "Objective Loss(ev): 0.11950613558292389\n",
      "Paramiters: lambda_spv = 31.701572814723477, lambda_sv = 75.85657694749534, rho = 1\n",
      "---------------------------\n",
      "Epoch: 490\n",
      "Total Loss: 9.031807899475098\n",
      "SPV: 0.0512644462287426\n",
      "SV: 0.0955057367682457\n",
      "Objective Loss(ev): 0.09449149668216705\n",
      "Paramiters: lambda_spv = 32.027635521953925, lambda_sv = 76.51044549234211, rho = 1\n",
      "---------------------------\n",
      "Epoch: 500\n",
      "Total Loss: 5.014735221862793\n",
      "SPV: 0.036859702318906784\n",
      "SV: 0.048908792436122894\n",
      "Objective Loss(ev): 0.046914152801036835\n",
      "Paramiters: lambda_spv = 32.378356497501954, lambda_sv = 77.24817982129753, rho = 1\n",
      "---------------------------\n",
      "Epoch: 510\n",
      "Total Loss: 8.179044723510742\n",
      "SPV: 0.03370003402233124\n",
      "SV: 0.08841614425182343\n",
      "Objective Loss(ev): 0.1800033152103424\n",
      "Paramiters: lambda_spv = 32.888042982434854, lambda_sv = 78.0362774785608, rho = 1\n",
      "---------------------------\n",
      "Epoch: 520\n",
      "Total Loss: 7.525505542755127\n",
      "SPV: 0.033388324081897736\n",
      "SV: 0.08047151565551758\n",
      "Objective Loss(ev): 0.09119772166013718\n",
      "Paramiters: lambda_spv = 33.23759867972694, lambda_sv = 78.68809749372303, rho = 1\n",
      "---------------------------\n",
      "Epoch: 530\n",
      "Total Loss: 3.9940080642700195\n",
      "SPV: 0.014576444402337074\n",
      "SV: 0.04242841526865959\n",
      "Objective Loss(ev): 0.14772945642471313\n",
      "Paramiters: lambda_spv = 33.52892870618962, lambda_sv = 79.18181793577969, rho = 1\n",
      "---------------------------\n",
      "Epoch: 540\n",
      "Total Loss: 5.232147216796875\n",
      "SPV: 0.008642473258078098\n",
      "SV: 0.06164105236530304\n",
      "Objective Loss(ev): 0.030270259827375412\n",
      "Paramiters: lambda_spv = 33.80410910653882, lambda_sv = 79.71310978196561, rho = 1\n",
      "---------------------------\n",
      "Epoch: 550\n",
      "Total Loss: 5.730344772338867\n",
      "SPV: 0.08369229733943939\n",
      "SV: 0.0352829173207283\n",
      "Objective Loss(ev): 0.04414060711860657\n",
      "Paramiters: lambda_spv = 34.23880800860934, lambda_sv = 80.17842511087656, rho = 1\n",
      "---------------------------\n",
      "Epoch: 560\n",
      "Total Loss: 5.825131416320801\n",
      "SPV: 0.05779765546321869\n",
      "SV: 0.04630020260810852\n",
      "Objective Loss(ev): 0.07933061569929123\n",
      "Paramiters: lambda_spv = 34.81602388317697, lambda_sv = 80.75558905676007, rho = 1\n",
      "---------------------------\n",
      "Epoch: 570\n",
      "Total Loss: 5.255281448364258\n",
      "SPV: 0.02043612115085125\n",
      "SV: 0.05434630811214447\n",
      "Objective Loss(ev): 0.12019092589616776\n",
      "Paramiters: lambda_spv = 35.24662862229161, lambda_sv = 81.29635840281844, rho = 1\n",
      "---------------------------\n",
      "Epoch: 580\n",
      "Total Loss: 4.889926910400391\n",
      "SPV: 0.012440278194844723\n",
      "SV: 0.05358335003256798\n",
      "Objective Loss(ev): 0.060157179832458496\n",
      "Paramiters: lambda_spv = 35.618997333338484, lambda_sv = 81.92255387455225, rho = 1\n",
      "---------------------------\n",
      "Epoch: 590\n",
      "Total Loss: 5.739004135131836\n",
      "SPV: 0.018995704129338264\n",
      "SV: 0.06005668267607689\n",
      "Objective Loss(ev): 0.10603444278240204\n",
      "Paramiters: lambda_spv = 35.921143950661644, lambda_sv = 82.49856158718467, rho = 1\n",
      "---------------------------\n",
      "Epoch: 600\n",
      "Total Loss: 10.027904510498047\n",
      "SPV: 0.022365063428878784\n",
      "SV: 0.11041352152824402\n",
      "Objective Loss(ev): 0.03378007560968399\n",
      "Paramiters: lambda_spv = 36.32792207575403, lambda_sv = 83.27186600863934, rho = 1\n",
      "---------------------------\n",
      "Epoch: 610\n",
      "Total Loss: 3.776437759399414\n",
      "SPV: 0.01321692205965519\n",
      "SV: 0.037979450076818466\n",
      "Objective Loss(ev): 0.10881195217370987\n",
      "Paramiters: lambda_spv = 36.61999784572981, lambda_sv = 83.86744670569897, rho = 1\n",
      "---------------------------\n",
      "Epoch: 620\n",
      "Total Loss: 5.273577690124512\n",
      "SPV: 0.042842067778110504\n",
      "SV: 0.04300878196954727\n",
      "Objective Loss(ev): 0.06523226201534271\n",
      "Paramiters: lambda_spv = 36.92247204645537, lambda_sv = 84.4059092067182, rho = 1\n",
      "---------------------------\n",
      "Epoch: 630\n",
      "Total Loss: 7.013969421386719\n",
      "SPV: 0.06655756384134293\n",
      "SV: 0.05192342400550842\n",
      "Objective Loss(ev): 0.11106954514980316\n",
      "Paramiters: lambda_spv = 37.46896768338047, lambda_sv = 85.05184394493699, rho = 1\n",
      "---------------------------\n",
      "Epoch: 640\n",
      "Total Loss: 3.739150285720825\n",
      "SPV: 0.014354542829096317\n",
      "SV: 0.03612259030342102\n",
      "Objective Loss(ev): 0.10707302391529083\n",
      "Paramiters: lambda_spv = 37.78039091336541, lambda_sv = 85.57713476195931, rho = 1\n",
      "---------------------------\n",
      "Epoch: 650\n",
      "Total Loss: 9.05309772491455\n",
      "SPV: 0.12437468022108078\n",
      "SV: 0.048997148871421814\n",
      "Objective Loss(ev): 0.09541912376880646\n",
      "Paramiters: lambda_spv = 38.2269183981698, lambda_sv = 86.14966045692563, rho = 1\n",
      "---------------------------\n",
      "Epoch: 660\n",
      "Total Loss: 9.111251831054688\n",
      "SPV: 0.03165992721915245\n",
      "SV: 0.09019985795021057\n",
      "Objective Loss(ev): 0.07416057586669922\n",
      "Paramiters: lambda_spv = 38.60652267723344, lambda_sv = 86.74015218019485, rho = 1\n",
      "---------------------------\n",
      "Epoch: 670\n",
      "Total Loss: 7.37721061706543\n",
      "SPV: 0.04541213810443878\n",
      "SV: 0.06256023049354553\n",
      "Objective Loss(ev): 0.16111212968826294\n",
      "Paramiters: lambda_spv = 38.83015730488114, lambda_sv = 87.25535238906741, rho = 1\n",
      "---------------------------\n",
      "Epoch: 680\n",
      "Total Loss: 4.731853008270264\n",
      "SPV: 0.017734451219439507\n",
      "SV: 0.04493214190006256\n",
      "Objective Loss(ev): 0.08397027850151062\n",
      "Paramiters: lambda_spv = 39.31475444021635, lambda_sv = 87.97690065950155, rho = 1\n",
      "---------------------------\n",
      "Epoch: 690\n",
      "Total Loss: 7.904007911682129\n",
      "SPV: 0.10114705562591553\n",
      "SV: 0.04303096979856491\n",
      "Objective Loss(ev): 0.0967024639248848\n",
      "Paramiters: lambda_spv = 39.679610705701634, lambda_sv = 88.44587805494666, rho = 1\n",
      "---------------------------\n",
      "Epoch: 700\n",
      "Total Loss: 6.8208441734313965\n",
      "SPV: 0.017182782292366028\n",
      "SV: 0.0681646466255188\n",
      "Objective Loss(ev): 0.07185837626457214\n",
      "Paramiters: lambda_spv = 39.970873539103195, lambda_sv = 89.00678470730782, rho = 1\n",
      "---------------------------\n",
      "Epoch: 710\n",
      "Total Loss: 9.406675338745117\n",
      "SPV: 0.05145368352532387\n",
      "SV: 0.08102976530790329\n",
      "Objective Loss(ev): 0.08965347707271576\n",
      "Paramiters: lambda_spv = 40.279327645665035, lambda_sv = 89.5191313996911, rho = 1\n",
      "---------------------------\n",
      "Epoch: 720\n",
      "Total Loss: 5.598726749420166\n",
      "SPV: 0.013479098677635193\n",
      "SV: 0.05584505572915077\n",
      "Objective Loss(ev): 0.02990960329771042\n",
      "Paramiters: lambda_spv = 40.5576776068192, lambda_sv = 89.98891651630402, rho = 1\n",
      "---------------------------\n",
      "Epoch: 730\n",
      "Total Loss: 8.31618595123291\n",
      "SPV: 0.020421534776687622\n",
      "SV: 0.08169083297252655\n",
      "Objective Loss(ev): 0.0924513190984726\n",
      "Paramiters: lambda_spv = 40.887362795649096, lambda_sv = 90.53455171361566, rho = 1\n",
      "---------------------------\n",
      "Epoch: 740\n",
      "Total Loss: 5.7319793701171875\n",
      "SPV: 0.022844109684228897\n",
      "SV: 0.05227573215961456\n",
      "Objective Loss(ev): 0.03556416928768158\n",
      "Paramiters: lambda_spv = 41.12721951282583, lambda_sv = 91.05858559533954, rho = 1\n",
      "---------------------------\n",
      "Epoch: 750\n",
      "Total Loss: 6.25963020324707\n",
      "SPV: 0.022170057520270348\n",
      "SV: 0.05701454356312752\n",
      "Objective Loss(ev): 0.11727913469076157\n",
      "Paramiters: lambda_spv = 41.51371309137903, lambda_sv = 91.65612661466002, rho = 1\n",
      "---------------------------\n",
      "Epoch: 760\n",
      "Total Loss: 5.368055820465088\n",
      "SPV: 0.01732090301811695\n",
      "SV: 0.04946516454219818\n",
      "Objective Loss(ev): 0.08850891888141632\n",
      "Paramiters: lambda_spv = 41.786594970850274, lambda_sv = 92.1560110412538, rho = 1\n",
      "---------------------------\n",
      "Epoch: 770\n",
      "Total Loss: 4.343855857849121\n",
      "SPV: 0.011391938664019108\n",
      "SV: 0.04100341349840164\n",
      "Objective Loss(ev): 0.0658656656742096\n",
      "Paramiters: lambda_spv = 42.089227388380095, lambda_sv = 92.68310607224703, rho = 1\n",
      "---------------------------\n",
      "Epoch: 780\n",
      "Total Loss: 6.039984226226807\n",
      "SPV: 0.01671813428401947\n",
      "SV: 0.057026565074920654\n",
      "Objective Loss(ev): 0.02283228375017643\n",
      "Paramiters: lambda_spv = 42.2816671601031, lambda_sv = 93.18134644627571, rho = 1\n",
      "---------------------------\n",
      "Epoch: 790\n",
      "Total Loss: 6.282521724700928\n",
      "SPV: 0.05890871211886406\n",
      "SV: 0.039565928280353546\n",
      "Objective Loss(ev): 0.07753060758113861\n",
      "Paramiters: lambda_spv = 42.554549254709855, lambda_sv = 93.59551918692887, rho = 1\n",
      "---------------------------\n",
      "Epoch: 800\n",
      "Total Loss: 4.782923698425293\n",
      "SPV: 0.05369732901453972\n",
      "SV: 0.025954965502023697\n",
      "Objective Loss(ev): 0.032175686210393906\n",
      "Paramiters: lambda_spv = 43.04561915085651, lambda_sv = 94.11957494169474, rho = 1\n",
      "---------------------------\n",
      "Epoch: 810\n",
      "Total Loss: 7.8428730964660645\n",
      "SPV: 0.028206758201122284\n",
      "SV: 0.06902329623699188\n",
      "Objective Loss(ev): 0.08771395683288574\n",
      "Paramiters: lambda_spv = 43.32277121418156, lambda_sv = 94.73212298937142, rho = 1\n",
      "---------------------------\n",
      "Epoch: 820\n",
      "Total Loss: 6.113589763641357\n",
      "SPV: 0.04091586917638779\n",
      "SV: 0.044499482959508896\n",
      "Objective Loss(ev): 0.08723244071006775\n",
      "Paramiters: lambda_spv = 43.707335617626086, lambda_sv = 95.31993244029582, rho = 1\n",
      "---------------------------\n",
      "Epoch: 830\n",
      "Total Loss: 8.032455444335938\n",
      "SPV: 0.07423269748687744\n",
      "SV: 0.04919418692588806\n",
      "Objective Loss(ev): 0.057872142642736435\n",
      "Paramiters: lambda_spv = 44.020709494827315, lambda_sv = 95.83931714110076, rho = 1\n",
      "---------------------------\n",
      "Epoch: 840\n",
      "Total Loss: 5.670322418212891\n",
      "SPV: 0.014180410653352737\n",
      "SV: 0.051825396716594696\n",
      "Objective Loss(ev): 0.05267152562737465\n",
      "Paramiters: lambda_spv = 44.374818802578375, lambda_sv = 96.30963344871998, rho = 1\n",
      "---------------------------\n",
      "Epoch: 850\n",
      "Total Loss: 10.695009231567383\n",
      "SPV: 0.11078663915395737\n",
      "SV: 0.058182768523693085\n",
      "Objective Loss(ev): 0.11360037326812744\n",
      "Paramiters: lambda_spv = 44.82017283770256, lambda_sv = 96.791399307549, rho = 1\n",
      "---------------------------\n",
      "Epoch: 860\n",
      "Total Loss: 5.7843122482299805\n",
      "SPV: 0.02109098993241787\n",
      "SV: 0.04913129657506943\n",
      "Objective Loss(ev): 0.04920565336942673\n",
      "Paramiters: lambda_spv = 45.11770289693959, lambda_sv = 97.42035575583577, rho = 1\n",
      "---------------------------\n",
      "Epoch: 870\n",
      "Total Loss: 4.831459999084473\n",
      "SPV: 0.015630751848220825\n",
      "SV: 0.04146979749202728\n",
      "Objective Loss(ev): 0.058178313076496124\n",
      "Paramiters: lambda_spv = 45.632034360663965, lambda_sv = 97.95039123296738, rho = 1\n",
      "---------------------------\n",
      "Epoch: 880\n",
      "Total Loss: 7.144763469696045\n",
      "SPV: 0.023711323738098145\n",
      "SV: 0.06126205623149872\n",
      "Objective Loss(ev): 0.02683570235967636\n",
      "Paramiters: lambda_spv = 46.04981928621419, lambda_sv = 98.43516118451953, rho = 1\n",
      "---------------------------\n",
      "Epoch: 890\n",
      "Total Loss: 4.585485458374023\n",
      "SPV: 0.013786617666482925\n",
      "SV: 0.039540715515613556\n",
      "Objective Loss(ev): 0.03862147405743599\n",
      "Paramiters: lambda_spv = 46.21191641804762, lambda_sv = 98.92365044355392, rho = 1\n",
      "---------------------------\n",
      "Epoch: 900\n",
      "Total Loss: 6.353154182434082\n",
      "SPV: 0.022719746455550194\n",
      "SV: 0.05255463719367981\n",
      "Objective Loss(ev): 0.0799388438463211\n",
      "Paramiters: lambda_spv = 46.442741732345894, lambda_sv = 99.35043475218117, rho = 1\n",
      "---------------------------\n",
      "Epoch: 910\n",
      "Total Loss: 7.810075759887695\n",
      "SPV: 0.04311545193195343\n",
      "SV: 0.057752542197704315\n",
      "Objective Loss(ev): 0.0415341779589653\n",
      "Paramiters: lambda_spv = 46.67190217296593, lambda_sv = 99.76108227670193, rho = 1\n",
      "---------------------------\n",
      "Epoch: 920\n",
      "Total Loss: 3.9807674884796143\n",
      "SPV: 0.02375199645757675\n",
      "SV: 0.028191106393933296\n",
      "Objective Loss(ev): 0.04110431671142578\n",
      "Paramiters: lambda_spv = 46.992840168764815, lambda_sv = 100.20352664031088, rho = 1\n",
      "---------------------------\n",
      "Epoch: 930\n",
      "Total Loss: 6.415344715118408\n",
      "SPV: 0.026270832866430283\n",
      "SV: 0.050422318279743195\n",
      "Objective Loss(ev): 0.09090203046798706\n",
      "Paramiters: lambda_spv = 47.52003187662922, lambda_sv = 100.73484990559518, rho = 1\n",
      "---------------------------\n",
      "Epoch: 940\n",
      "Total Loss: 6.229621887207031\n",
      "SPV: 0.028536710888147354\n",
      "SV: 0.04759291559457779\n",
      "Objective Loss(ev): 0.04542456567287445\n",
      "Paramiters: lambda_spv = 47.887545907637104, lambda_sv = 101.2907957341522, rho = 1\n",
      "---------------------------\n",
      "Epoch: 950\n",
      "Total Loss: 5.580258369445801\n",
      "SPV: 0.017891453579068184\n",
      "SV: 0.04584762454032898\n",
      "Objective Loss(ev): 0.052983593195676804\n",
      "Paramiters: lambda_spv = 48.0923927614931, lambda_sv = 101.8428809363395, rho = 1\n",
      "---------------------------\n",
      "Epoch: 960\n",
      "Total Loss: 6.1568098068237305\n",
      "SPV: 0.023216690868139267\n",
      "SV: 0.047928549349308014\n",
      "Objective Loss(ev): 0.13274195790290833\n",
      "Paramiters: lambda_spv = 48.4982968934346, lambda_sv = 102.25500711612403, rho = 1\n",
      "---------------------------\n",
      "Epoch: 970\n",
      "Total Loss: 6.224576950073242\n",
      "SPV: 0.0058203088119626045\n",
      "SV: 0.056630246341228485\n",
      "Objective Loss(ev): 0.12934261560440063\n",
      "Paramiters: lambda_spv = 48.624879034934565, lambda_sv = 102.69182579033077, rho = 1\n",
      "---------------------------\n",
      "Epoch: 980\n",
      "Total Loss: 10.345965385437012\n",
      "SPV: 0.08921250700950623\n",
      "SV: 0.05735037848353386\n",
      "Objective Loss(ev): 0.07188722491264343\n",
      "Paramiters: lambda_spv = 48.95679723541252, lambda_sv = 103.18620996922255, rho = 1\n",
      "---------------------------\n",
      "Epoch: 990\n",
      "Total Loss: 6.383718967437744\n",
      "SPV: 0.03285730257630348\n",
      "SV: 0.04526516795158386\n",
      "Objective Loss(ev): 0.0723675787448883\n",
      "Paramiters: lambda_spv = 49.25368208414875, lambda_sv = 103.7472562212497, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1000\n",
      "Total Loss: 5.170773029327393\n",
      "SPV: 0.0047028264962136745\n",
      "SV: 0.04636558145284653\n",
      "Objective Loss(ev): 0.10276299715042114\n",
      "Paramiters: lambda_spv = 49.67522134468891, lambda_sv = 104.31376289296895, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1010\n",
      "Total Loss: 4.994335174560547\n",
      "SPV: 0.02897985838353634\n",
      "SV: 0.03322075679898262\n",
      "Objective Loss(ev): 0.06751391291618347\n",
      "Paramiters: lambda_spv = 49.98938933084719, lambda_sv = 104.75617467518896, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1020\n",
      "Total Loss: 2.88409161567688\n",
      "SPV: 0.017720792442560196\n",
      "SV: 0.018522707745432854\n",
      "Objective Loss(ev): 0.0474349744617939\n",
      "Paramiters: lambda_spv = 50.207371116383, lambda_sv = 105.14659246522933, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1030\n",
      "Total Loss: 5.5404815673828125\n",
      "SPV: 0.035908084362745285\n",
      "SV: 0.03459787368774414\n",
      "Objective Loss(ev): 0.07559714466333389\n",
      "Paramiters: lambda_spv = 50.51268107141368, lambda_sv = 105.6006343504414, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1040\n",
      "Total Loss: 9.030717849731445\n",
      "SPV: 0.08199755847454071\n",
      "SV: 0.04547297954559326\n",
      "Objective Loss(ev): 0.0368860699236393\n",
      "Paramiters: lambda_spv = 50.92362586478703, lambda_sv = 106.15118823107332, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1050\n",
      "Total Loss: 6.838370323181152\n",
      "SPV: 0.02601151540875435\n",
      "SV: 0.05160827934741974\n",
      "Objective Loss(ev): 0.011520149186253548\n",
      "Paramiters: lambda_spv = 51.19568355451338, lambda_sv = 106.54321559797972, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1060\n",
      "Total Loss: 10.158821105957031\n",
      "SPV: 0.09104438126087189\n",
      "SV: 0.05012466013431549\n",
      "Objective Loss(ev): 0.09892184287309647\n",
      "Paramiters: lambda_spv = 51.69646121072583, lambda_sv = 107.01377016212791, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1070\n",
      "Total Loss: 10.764686584472656\n",
      "SPV: 0.04304761812090874\n",
      "SV: 0.07869218289852142\n",
      "Objective Loss(ev): 0.06968861073255539\n",
      "Paramiters: lambda_spv = 52.100436764536425, lambda_sv = 107.51059880573303, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1080\n",
      "Total Loss: 4.561067581176758\n",
      "SPV: 0.029260095208883286\n",
      "SV: 0.027460219338536263\n",
      "Objective Loss(ev): 0.06340178847312927\n",
      "Paramiters: lambda_spv = 52.49213794874959, lambda_sv = 107.91432017739862, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1090\n",
      "Total Loss: 5.081766128540039\n",
      "SPV: 0.02549077197909355\n",
      "SV: 0.03392333164811134\n",
      "Objective Loss(ev): 0.0627443715929985\n",
      "Paramiters: lambda_spv = 52.77734165894799, lambda_sv = 108.34687448758632, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1100\n",
      "Total Loss: 5.720190048217773\n",
      "SPV: 0.013375794515013695\n",
      "SV: 0.04521840810775757\n",
      "Objective Loss(ev): 0.09246982634067535\n",
      "Paramiters: lambda_spv = 53.08750517270528, lambda_sv = 108.80207447614521, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1110\n",
      "Total Loss: 9.952213287353516\n",
      "SPV: 0.11495347321033478\n",
      "SV: 0.03390543907880783\n",
      "Objective Loss(ev): 0.11709368228912354\n",
      "Paramiters: lambda_spv = 53.45717064826749, lambda_sv = 109.2566456431523, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1120\n",
      "Total Loss: 6.293255805969238\n",
      "SPV: 0.0181964673101902\n",
      "SV: 0.047816596925258636\n",
      "Objective Loss(ev): 0.07774502038955688\n",
      "Paramiters: lambda_spv = 53.61174327577464, lambda_sv = 109.63941255304962, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1130\n",
      "Total Loss: 4.483193397521973\n",
      "SPV: 0.02964654192328453\n",
      "SV: 0.025506962090730667\n",
      "Objective Loss(ev): 0.08318699896335602\n",
      "Paramiters: lambda_spv = 53.81948665971868, lambda_sv = 110.00815427582711, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1140\n",
      "Total Loss: 6.559109210968018\n",
      "SPV: 0.04942832887172699\n",
      "SV: 0.034841254353523254\n",
      "Objective Loss(ev): 0.04323317110538483\n",
      "Paramiters: lambda_spv = 54.08882864797488, lambda_sv = 110.38673748355359, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1150\n",
      "Total Loss: 4.05156946182251\n",
      "SPV: 0.007715536281466484\n",
      "SV: 0.032059162855148315\n",
      "Objective Loss(ev): 0.08277721703052521\n",
      "Paramiters: lambda_spv = 54.3483094223775, lambda_sv = 110.75004001241177, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1160\n",
      "Total Loss: 6.177057266235352\n",
      "SPV: 0.05984342843294144\n",
      "SV: 0.02540116012096405\n",
      "Objective Loss(ev): 0.08968593180179596\n",
      "Paramiters: lambda_spv = 54.590450272895396, lambda_sv = 111.20429424848408, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1170\n",
      "Total Loss: 4.8682966232299805\n",
      "SPV: 0.012053555808961391\n",
      "SV: 0.03723780810832977\n",
      "Objective Loss(ev): 0.04917886108160019\n",
      "Paramiters: lambda_spv = 54.842413700185716, lambda_sv = 111.7037706328556, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1180\n",
      "Total Loss: 4.225167274475098\n",
      "SPV: 0.008919542655348778\n",
      "SV: 0.03217506408691406\n",
      "Objective Loss(ev): 0.12583884596824646\n",
      "Paramiters: lambda_spv = 55.10476930066943, lambda_sv = 112.16556236799806, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1190\n",
      "Total Loss: 16.808258056640625\n",
      "SPV: 0.1439015418291092\n",
      "SV: 0.07768823951482773\n",
      "Objective Loss(ev): 0.06703066825866699\n",
      "Paramiters: lambda_spv = 55.6874858494848, lambda_sv = 112.6870004562661, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1200\n",
      "Total Loss: 13.375715255737305\n",
      "SPV: 0.053320303559303284\n",
      "SV: 0.09105562418699265\n",
      "Objective Loss(ev): 0.06652450561523438\n",
      "Paramiters: lambda_spv = 56.060654795728624, lambda_sv = 113.45981031563133, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1210\n",
      "Total Loss: 6.699244499206543\n",
      "SPV: 0.024271328002214432\n",
      "SV: 0.04612977057695389\n",
      "Objective Loss(ev): 0.07801924645900726\n",
      "Paramiters: lambda_spv = 56.34303315449506, lambda_sv = 113.94858965370804, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1220\n",
      "Total Loss: 12.225252151489258\n",
      "SPV: 0.05769217759370804\n",
      "SV: 0.07781516015529633\n",
      "Objective Loss(ev): 0.06383512914180756\n",
      "Paramiters: lambda_spv = 56.576949320267886, lambda_sv = 114.4603912057355, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1230\n",
      "Total Loss: 6.418984413146973\n",
      "SPV: 0.027130596339702606\n",
      "SV: 0.041961926966905594\n",
      "Objective Loss(ev): 0.05157474800944328\n",
      "Paramiters: lambda_spv = 56.86719059897587, lambda_sv = 115.03441230673343, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1240\n",
      "Total Loss: 10.344839096069336\n",
      "SPV: 0.051020026206970215\n",
      "SV: 0.06358061730861664\n",
      "Objective Loss(ev): 0.09688303619623184\n",
      "Paramiters: lambda_spv = 57.09964158991352, lambda_sv = 115.46562993060797, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1250\n",
      "Total Loss: 4.95625114440918\n",
      "SPV: 0.008761356584727764\n",
      "SV: 0.03745178133249283\n",
      "Objective Loss(ev): 0.11677246540784836\n",
      "Paramiters: lambda_spv = 57.27223110513296, lambda_sv = 115.86031416151673, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1260\n",
      "Total Loss: 1.9750703573226929\n",
      "SPV: 0.005416445899754763\n",
      "SV: 0.013756568543612957\n",
      "Objective Loss(ev): 0.06585618853569031\n",
      "Paramiters: lambda_spv = 57.40589147468563, lambda_sv = 116.19880646467209, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1270\n",
      "Total Loss: 6.204737663269043\n",
      "SPV: 0.017405766993761063\n",
      "SV: 0.044264744967222214\n",
      "Objective Loss(ev): 0.042715732008218765\n",
      "Paramiters: lambda_spv = 57.60440955252852, lambda_sv = 116.60827674902976, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1280\n",
      "Total Loss: 6.221309185028076\n",
      "SPV: 0.02160409465432167\n",
      "SV: 0.04172114282846451\n",
      "Objective Loss(ev): 0.09050212800502777\n",
      "Paramiters: lambda_spv = 57.8421078681713, lambda_sv = 117.04827536828816, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1290\n",
      "Total Loss: 4.9201130867004395\n",
      "SPV: 0.00518561527132988\n",
      "SV: 0.0386161245405674\n",
      "Objective Loss(ev): 0.08562307804822922\n",
      "Paramiters: lambda_spv = 57.9622670620447, lambda_sv = 117.44934001378715, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1300\n",
      "Total Loss: 8.61978530883789\n",
      "SPV: 0.06049318239092827\n",
      "SV: 0.04265972971916199\n",
      "Objective Loss(ev): 0.0746121034026146\n",
      "Paramiters: lambda_spv = 58.2669824360637, lambda_sv = 117.81362872570753, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1310\n",
      "Total Loss: 11.406028747558594\n",
      "SPV: 0.050429604947566986\n",
      "SV: 0.07103350013494492\n",
      "Objective Loss(ev): 0.054109130054712296\n",
      "Paramiters: lambda_spv = 58.56196600792464, lambda_sv = 118.34206322580576, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1320\n",
      "Total Loss: 7.814709663391113\n",
      "SPV: 0.006893712095916271\n",
      "SV: 0.062171272933483124\n",
      "Objective Loss(ev): 0.02889677882194519\n",
      "Paramiters: lambda_spv = 58.79415826674085, lambda_sv = 118.77536331675947, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1330\n",
      "Total Loss: 8.232284545898438\n",
      "SPV: 0.04832401126623154\n",
      "SV: 0.04437489062547684\n",
      "Objective Loss(ev): 0.09529164433479309\n",
      "Paramiters: lambda_spv = 59.017246169853024, lambda_sv = 119.1968392059207, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1340\n",
      "Total Loss: 6.355316162109375\n",
      "SPV: 0.010137997567653656\n",
      "SV: 0.04773633927106857\n",
      "Objective Loss(ev): 0.0461437851190567\n",
      "Paramiters: lambda_spv = 59.42799572169315, lambda_sv = 119.59594766423106, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1350\n",
      "Total Loss: 8.894357681274414\n",
      "SPV: 0.018223857507109642\n",
      "SV: 0.0640546903014183\n",
      "Objective Loss(ev): 0.13162778317928314\n",
      "Paramiters: lambda_spv = 59.5577634080546, lambda_sv = 119.92552647460252, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1360\n",
      "Total Loss: 2.4545302391052246\n",
      "SPV: 0.01136431097984314\n",
      "SV: 0.014261150732636452\n",
      "Objective Loss(ev): 0.05812931805849075\n",
      "Paramiters: lambda_spv = 59.8601459042402, lambda_sv = 120.359440500848, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1370\n",
      "Total Loss: 4.886171340942383\n",
      "SPV: 0.025582415983080864\n",
      "SV: 0.0274356659501791\n",
      "Objective Loss(ev): 0.03745631128549576\n",
      "Paramiters: lambda_spv = 60.133324630209245, lambda_sv = 120.71026098635048, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1380\n",
      "Total Loss: 3.9060540199279785\n",
      "SPV: 0.014223195612430573\n",
      "SV: 0.024537021294236183\n",
      "Objective Loss(ev): 0.08027449250221252\n",
      "Paramiters: lambda_spv = 60.2889716863865, lambda_sv = 121.00417463574558, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1390\n",
      "Total Loss: 3.024540901184082\n",
      "SPV: 0.025079229846596718\n",
      "SV: 0.011951792985200882\n",
      "Objective Loss(ev): 0.05813061445951462\n",
      "Paramiters: lambda_spv = 60.50971676467452, lambda_sv = 121.29101509321481, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1400\n",
      "Total Loss: 19.72123908996582\n",
      "SPV: 0.21627572178840637\n",
      "SV: 0.05320034921169281\n",
      "Objective Loss(ev): 0.05077371746301651\n",
      "Paramiters: lambda_spv = 61.24619622819591, lambda_sv = 121.69103978201747, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1410\n",
      "Total Loss: 18.39212417602539\n",
      "SPV: 0.01175856962800026\n",
      "SV: 0.14382411539554596\n",
      "Objective Loss(ev): 0.10017475485801697\n",
      "Paramiters: lambda_spv = 61.81623287044931, lambda_sv = 122.27367026358843, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1420\n",
      "Total Loss: 8.8145170211792\n",
      "SPV: 0.030224744230508804\n",
      "SV: 0.05579230189323425\n",
      "Objective Loss(ev): 0.09228406846523285\n",
      "Paramiters: lambda_spv = 62.049581194412895, lambda_sv = 122.7916038390249, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1430\n",
      "Total Loss: 6.50450325012207\n",
      "SPV: 0.002419165801256895\n",
      "SV: 0.05113239213824272\n",
      "Objective Loss(ev): 0.05757681280374527\n",
      "Paramiters: lambda_spv = 62.48000710422639, lambda_sv = 123.17822052538395, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1440\n",
      "Total Loss: 8.119613647460938\n",
      "SPV: 0.03570075333118439\n",
      "SV: 0.046871963888406754\n",
      "Objective Loss(ev): 0.0815664529800415\n",
      "Paramiters: lambda_spv = 62.83401698304806, lambda_sv = 123.70501928403974, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1450\n",
      "Total Loss: 9.302817344665527\n",
      "SPV: 0.03046766296029091\n",
      "SV: 0.058349788188934326\n",
      "Objective Loss(ev): 0.14550699293613434\n",
      "Paramiters: lambda_spv = 63.03111914603505, lambda_sv = 124.10040044039488, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1460\n",
      "Total Loss: 7.555253982543945\n",
      "SPV: 0.029555421322584152\n",
      "SV: 0.04499248042702675\n",
      "Objective Loss(ev): 0.0823819488286972\n",
      "Paramiters: lambda_spv = 63.384046286926605, lambda_sv = 124.51919370517135, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1470\n",
      "Total Loss: 5.391993522644043\n",
      "SPV: 0.03818794712424278\n",
      "SV: 0.02307428978383541\n",
      "Objective Loss(ev): 0.07909297943115234\n",
      "Paramiters: lambda_spv = 63.67712935304735, lambda_sv = 124.95260394364595, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1480\n",
      "Total Loss: 8.230737686157227\n",
      "SPV: 0.0031566419638693333\n",
      "SV: 0.06321267038583755\n",
      "Objective Loss(ev): 0.10320679098367691\n",
      "Paramiters: lambda_spv = 63.967130435514264, lambda_sv = 125.44344433955848, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1490\n",
      "Total Loss: 4.4281110763549805\n",
      "SPV: 0.006096296943724155\n",
      "SV: 0.031810931861400604\n",
      "Objective Loss(ev): 0.037792548537254333\n",
      "Paramiters: lambda_spv = 64.14529923710506, lambda_sv = 125.75294800661504, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1500\n",
      "Total Loss: 6.285241603851318\n",
      "SPV: 0.04285992309451103\n",
      "SV: 0.0270728450268507\n",
      "Objective Loss(ev): 0.11694193631410599\n",
      "Paramiters: lambda_spv = 64.32924130081665, lambda_sv = 126.09399783983827, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1510\n",
      "Total Loss: 5.118843078613281\n",
      "SPV: 0.005482173524796963\n",
      "SV: 0.037137921899557114\n",
      "Objective Loss(ev): 0.07047650218009949\n",
      "Paramiters: lambda_spv = 64.48049986769911, lambda_sv = 126.45517507754266, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1520\n",
      "Total Loss: 3.660271167755127\n",
      "SPV: 0.007580966223031282\n",
      "SV: 0.024173852056264877\n",
      "Objective Loss(ev): 0.10562290996313095\n",
      "Paramiters: lambda_spv = 64.63218512141611, lambda_sv = 126.80294729582965, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1530\n",
      "Total Loss: 13.004847526550293\n",
      "SPV: 0.06533726304769516\n",
      "SV: 0.06847067177295685\n",
      "Objective Loss(ev): 0.06538238376379013\n",
      "Paramiters: lambda_spv = 64.90704757568892, lambda_sv = 127.17229879740626, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1540\n",
      "Total Loss: 6.428720951080322\n",
      "SPV: 0.027217663824558258\n",
      "SV: 0.03599666431546211\n",
      "Objective Loss(ev): 0.07034097611904144\n",
      "Paramiters: lambda_spv = 65.1077112298226, lambda_sv = 127.46561487857252, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1550\n",
      "Total Loss: 7.8994669914245605\n",
      "SPV: 0.05012482404708862\n",
      "SV: 0.035880737006664276\n",
      "Objective Loss(ev): 0.03818594664335251\n",
      "Paramiters: lambda_spv = 65.40898400812875, lambda_sv = 127.82533897366375, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1560\n",
      "Total Loss: 10.992127418518066\n",
      "SPV: 0.051333051174879074\n",
      "SV: 0.05909044295549393\n",
      "Objective Loss(ev): 0.03731130063533783\n",
      "Paramiters: lambda_spv = 65.72356536414009, lambda_sv = 128.39896178152412, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1570\n",
      "Total Loss: 6.956925868988037\n",
      "SPV: 0.009847967885434628\n",
      "SV: 0.04836583137512207\n",
      "Objective Loss(ev): 0.07260656356811523\n",
      "Paramiters: lambda_spv = 66.0209540881915, lambda_sv = 128.94605903234333, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1580\n",
      "Total Loss: 6.654603004455566\n",
      "SPV: 0.009750817902386189\n",
      "SV: 0.04602288082242012\n",
      "Objective Loss(ev): 0.04979005083441734\n",
      "Paramiters: lambda_spv = 66.28751862829085, lambda_sv = 129.5153301684186, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1590\n",
      "Total Loss: 8.017538070678711\n",
      "SPV: 0.008393488824367523\n",
      "SV: 0.05681000277400017\n",
      "Objective Loss(ev): 0.08122120797634125\n",
      "Paramiters: lambda_spv = 66.49585044791456, lambda_sv = 129.93279782216996, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1600\n",
      "Total Loss: 2.909611701965332\n",
      "SPV: 0.017017245292663574\n",
      "SV: 0.01316116563975811\n",
      "Objective Loss(ev): 0.06296820938587189\n",
      "Paramiters: lambda_spv = 66.63950082182419, lambda_sv = 130.162155312486, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1610\n",
      "Total Loss: 6.910296440124512\n",
      "SPV: 0.045417871326208115\n",
      "SV: 0.029237497597932816\n",
      "Objective Loss(ev): 0.06145019084215164\n",
      "Paramiters: lambda_spv = 66.8304801977938, lambda_sv = 130.53325124364346, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1620\n",
      "Total Loss: 4.724813461303711\n",
      "SPV: 0.020358003675937653\n",
      "SV: 0.025001611560583115\n",
      "Objective Loss(ev): 0.08727644383907318\n",
      "Paramiters: lambda_spv = 67.09214231499936, lambda_sv = 130.90014032181352, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1630\n",
      "Total Loss: 2.5890493392944336\n",
      "SPV: 0.007756922394037247\n",
      "SV: 0.015133675187826157\n",
      "Objective Loss(ev): 0.08227603137493134\n",
      "Paramiters: lambda_spv = 67.2476468506502, lambda_sv = 131.1926941415295, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1640\n",
      "Total Loss: 6.10931921005249\n",
      "SPV: 0.033564500510692596\n",
      "SV: 0.028728224337100983\n",
      "Objective Loss(ev): 0.06915348768234253\n",
      "Paramiters: lambda_spv = 67.50254728284199, lambda_sv = 131.45357425510883, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1650\n",
      "Total Loss: 6.7542901039123535\n",
      "SPV: 0.03292449563741684\n",
      "SV: 0.03389115631580353\n",
      "Objective Loss(ev): 0.0619678869843483\n",
      "Paramiters: lambda_spv = 67.64226127264556, lambda_sv = 131.81809269823134, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1660\n",
      "Total Loss: 10.083830833435059\n",
      "SPV: 0.06340648978948593\n",
      "SV: 0.04348932206630707\n",
      "Objective Loss(ev): 0.03574927896261215\n",
      "Paramiters: lambda_spv = 67.86329134448897, lambda_sv = 132.2397909257561, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1670\n",
      "Total Loss: 9.169617652893066\n",
      "SPV: 0.026833530515432358\n",
      "SV: 0.05486166477203369\n",
      "Objective Loss(ev): 0.06649662554264069\n",
      "Paramiters: lambda_spv = 68.22060567291919, lambda_sv = 132.62906397879124, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1680\n",
      "Total Loss: 6.01922082901001\n",
      "SPV: 0.02942926250398159\n",
      "SV: 0.029204469174146652\n",
      "Objective Loss(ev): 0.11887793987989426\n",
      "Paramiters: lambda_spv = 68.49653590715025, lambda_sv = 133.07069926150143, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1690\n",
      "Total Loss: 6.0759358406066895\n",
      "SPV: 0.021520506590604782\n",
      "SV: 0.03407435119152069\n",
      "Objective Loss(ev): 0.04762936010956764\n",
      "Paramiters: lambda_spv = 68.91686965350527, lambda_sv = 133.4377233106643, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1700\n",
      "Total Loss: 4.006853103637695\n",
      "SPV: 0.0029396312311291695\n",
      "SV: 0.028120504692196846\n",
      "Objective Loss(ev): 0.04258967936038971\n",
      "Paramiters: lambda_spv = 69.13960053224582, lambda_sv = 133.77491681091487, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1710\n",
      "Total Loss: 9.444576263427734\n",
      "SPV: 0.058362334966659546\n",
      "SV: 0.03955192118883133\n",
      "Objective Loss(ev): 0.09844952821731567\n",
      "Paramiters: lambda_spv = 69.36068385711405, lambda_sv = 134.0780654270202, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1720\n",
      "Total Loss: 9.875448226928711\n",
      "SPV: 0.05568453669548035\n",
      "SV: 0.044001124799251556\n",
      "Objective Loss(ev): 0.0703497901558876\n",
      "Paramiters: lambda_spv = 69.88832920289133, lambda_sv = 134.5064949002117, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1730\n",
      "Total Loss: 7.4051103591918945\n",
      "SPV: 0.022185849025845528\n",
      "SV: 0.043014708906412125\n",
      "Objective Loss(ev): 0.03501711040735245\n",
      "Paramiters: lambda_spv = 70.32233711017761, lambda_sv = 135.1229523140937, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1740\n",
      "Total Loss: 4.959929466247559\n",
      "SPV: 0.016978461295366287\n",
      "SV: 0.02755807153880596\n",
      "Objective Loss(ev): 0.03145983815193176\n",
      "Paramiters: lambda_spv = 70.59498978185002, lambda_sv = 135.3840290894732, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1750\n",
      "Total Loss: 9.339256286621094\n",
      "SPV: 0.013049443252384663\n",
      "SV: 0.06173252686858177\n",
      "Objective Loss(ev): 0.03690585494041443\n",
      "Paramiters: lambda_spv = 70.86851524433587, lambda_sv = 135.7718114843592, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1760\n",
      "Total Loss: 14.798799514770508\n",
      "SPV: 0.0799374058842659\n",
      "SV: 0.06625291705131531\n",
      "Objective Loss(ev): 0.09770792722702026\n",
      "Paramiters: lambda_spv = 71.18874017579947, lambda_sv = 136.16348083876073, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1770\n",
      "Total Loss: 6.501354217529297\n",
      "SPV: 0.017703892663121223\n",
      "SV: 0.03803623095154762\n",
      "Objective Loss(ev): 0.04257053881883621\n",
      "Paramiters: lambda_spv = 71.462786380318, lambda_sv = 136.59015990234911, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1780\n",
      "Total Loss: 6.465329170227051\n",
      "SPV: 0.007083550561219454\n",
      "SV: 0.043115802109241486\n",
      "Objective Loss(ev): 0.05800863355398178\n",
      "Paramiters: lambda_spv = 71.57293529587332, lambda_sv = 136.89273049868643, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1790\n",
      "Total Loss: 5.959545612335205\n",
      "SPV: 0.023779308423399925\n",
      "SV: 0.0306264515966177\n",
      "Objective Loss(ev): 0.048160359263420105\n",
      "Paramiters: lambda_spv = 71.8115247922251, lambda_sv = 137.30811649560928, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1800\n",
      "Total Loss: 7.187372207641602\n",
      "SPV: 0.004189616069197655\n",
      "SV: 0.04942954331636429\n",
      "Objective Loss(ev): 0.08101686835289001\n",
      "Paramiters: lambda_spv = 72.01318307162728, lambda_sv = 137.7133506052196, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1810\n",
      "Total Loss: 10.795072555541992\n",
      "SPV: 0.07936456799507141\n",
      "SV: 0.035959720611572266\n",
      "Objective Loss(ev): 0.09131388366222382\n",
      "Paramiters: lambda_spv = 72.3393950156169, lambda_sv = 138.21478370204568, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1820\n",
      "Total Loss: 9.083015441894531\n",
      "SPV: 0.03421570360660553\n",
      "SV: 0.04677511379122734\n",
      "Objective Loss(ev): 0.1182466521859169\n",
      "Paramiters: lambda_spv = 72.5539380722912, lambda_sv = 138.6558504961431, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1830\n",
      "Total Loss: 7.8688554763793945\n",
      "SPV: 0.02266347035765648\n",
      "SV: 0.04417353868484497\n",
      "Objective Loss(ev): 0.08160850405693054\n",
      "Paramiters: lambda_spv = 72.73443116585258, lambda_sv = 139.02661617472768, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1840\n",
      "Total Loss: 5.334595680236816\n",
      "SPV: 0.019210949540138245\n",
      "SV: 0.02767268568277359\n",
      "Objective Loss(ev): 0.07932756841182709\n",
      "Paramiters: lambda_spv = 72.87205482536228, lambda_sv = 139.35987733863294, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1850\n",
      "Total Loss: 5.400625705718994\n",
      "SPV: 0.004685373976826668\n",
      "SV: 0.03606221824884415\n",
      "Objective Loss(ev): 0.02021605521440506\n",
      "Paramiters: lambda_spv = 73.10655891807983, lambda_sv = 139.73628098145127, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1860\n",
      "Total Loss: 5.0577073097229\n",
      "SPV: 0.009825039654970169\n",
      "SV: 0.030648674815893173\n",
      "Objective Loss(ev): 0.04723493382334709\n",
      "Paramiters: lambda_spv = 73.28346782742301, lambda_sv = 140.02221101988107, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1870\n",
      "Total Loss: 4.8343915939331055\n",
      "SPV: 0.008534512482583523\n",
      "SV: 0.02917761728167534\n",
      "Objective Loss(ev): 0.11370965838432312\n",
      "Paramiters: lambda_spv = 73.45360756997252, lambda_sv = 140.33753835130483, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1880\n",
      "Total Loss: 7.938687324523926\n",
      "SPV: 0.010477096773684025\n",
      "SV: 0.05046102777123451\n",
      "Objective Loss(ev): 0.07150866091251373\n",
      "Paramiters: lambda_spv = 73.60276516299928, lambda_sv = 140.67670979443938, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1890\n",
      "Total Loss: 7.037110328674316\n",
      "SPV: 0.028851289302110672\n",
      "SV: 0.033882249146699905\n",
      "Objective Loss(ev): 0.13195237517356873\n",
      "Paramiters: lambda_spv = 73.83990664459998, lambda_sv = 140.98125342279673, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1900\n",
      "Total Loss: 8.866682052612305\n",
      "SPV: 0.025922078639268875\n",
      "SV: 0.048580266535282135\n",
      "Objective Loss(ev): 0.07500109076499939\n",
      "Paramiters: lambda_spv = 74.23036167077953, lambda_sv = 141.42588867247105, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1910\n",
      "Total Loss: 9.147921562194824\n",
      "SPV: 0.03558078408241272\n",
      "SV: 0.04550158977508545\n",
      "Objective Loss(ev): 0.053858473896980286\n",
      "Paramiters: lambda_spv = 74.37816759158159, lambda_sv = 141.774500656873, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1920\n",
      "Total Loss: 3.8762993812561035\n",
      "SPV: 0.00789155624806881\n",
      "SV: 0.021975135430693626\n",
      "Objective Loss(ev): 0.16690748929977417\n",
      "Paramiters: lambda_spv = 74.63367553200806, lambda_sv = 142.02237625420094, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1930\n",
      "Total Loss: 5.6201605796813965\n",
      "SPV: 0.007329145912081003\n",
      "SV: 0.03532817214727402\n",
      "Objective Loss(ev): 0.04511919245123863\n",
      "Paramiters: lambda_spv = 74.77507267991314, lambda_sv = 142.33135209791362, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1940\n",
      "Total Loss: 5.370944976806641\n",
      "SPV: 0.04727720841765404\n",
      "SV: 0.01256076991558075\n",
      "Objective Loss(ev): 0.0370631068944931\n",
      "Paramiters: lambda_spv = 74.99835090973647, lambda_sv = 142.5519267595373, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1950\n",
      "Total Loss: 8.523478507995605\n",
      "SPV: 0.020090097561478615\n",
      "SV: 0.04857533797621727\n",
      "Objective Loss(ev): 0.0735783725976944\n",
      "Paramiters: lambda_spv = 75.11890529905213, lambda_sv = 142.94324154546484, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1960\n",
      "Total Loss: 6.232626438140869\n",
      "SPV: 0.0057876743376255035\n",
      "SV: 0.03964490070939064\n",
      "Objective Loss(ev): 0.11719340085983276\n",
      "Paramiters: lambda_spv = 75.29550950782141, lambda_sv = 143.30348947783932, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1970\n",
      "Total Loss: 2.6989424228668213\n",
      "SPV: 0.02628179080784321\n",
      "SV: 0.004358682781457901\n",
      "Objective Loss(ev): 0.08872810751199722\n",
      "Paramiters: lambda_spv = 75.52641544764629, lambda_sv = 143.61096496833488, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1980\n",
      "Total Loss: 8.430584907531738\n",
      "SPV: 0.015705958008766174\n",
      "SV: 0.04968973249197006\n",
      "Objective Loss(ev): 0.09054084122180939\n",
      "Paramiters: lambda_spv = 75.71954076917609, lambda_sv = 143.9636000865139, rho = 1\n",
      "---------------------------\n",
      "Epoch: 1990\n",
      "Total Loss: 11.501157760620117\n",
      "SPV: 0.024713806807994843\n",
      "SV: 0.06637069582939148\n",
      "Objective Loss(ev): 0.04668198525905609\n",
      "Paramiters: lambda_spv = 76.08145858248463, lambda_sv = 144.32920202380046, rho = 1\n",
      "---------------------------\n",
      "Epoch: 2000\n",
      "Total Loss: 6.8995866775512695\n",
      "SPV: 0.05155477672815323\n",
      "SV: 0.01982296258211136\n",
      "Objective Loss(ev): 0.093215711414814\n",
      "Paramiters: lambda_spv = 76.46193576295627, lambda_sv = 144.6526364008896, rho = 1\n",
      "---------------------------\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "train_model(cfg, model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_0120.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchingNet(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=18, out_features=64, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): Linear(in_features=64, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "\n",
    "p = torch.tensor([[[1, 0, 0.0], [0., 1, 0], [0., 0, 1]]],  dtype=torch.float32).to(device)\n",
    "q = torch.tensor([[[0, 0.0, 1], [0.0, 1, 0.0], [0.3, 0.3, 1]]],  dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "         [9.9657e-06, 0.0000e+00, 9.9999e-01]]], device='mps:0',\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = model(p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4611, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4510, 0.0000],\n",
       "        [0.0000, 0.0000, 0.4547]], device='mps:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sv(cfg, r, p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = list(itertools.permutations([3, 2, 1]))\n",
    "q_list = p_list + [(1,2,2), (2,1,2), (2,2,1),(1,1,2), (1,2,1), (2,1,1), (1,1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_1_1 = []\n",
    "pairs_1_2 = []\n",
    "pairs_1_3 = []\n",
    "pairs_2_1 = []\n",
    "pairs_2_2 = []\n",
    "pairs_2_3 = []\n",
    "pairs_3_1 = []\n",
    "pairs_3_2 = []\n",
    "pairs_3_3 = []\n",
    "\n",
    "p_set_1 = []\n",
    "p_set_2 = []\n",
    "p_set_3 = []\n",
    "q_set_1 = []\n",
    "q_set_2 = []\n",
    "q_set_3 = []\n",
    "\n",
    "for i in range(6):\n",
    "    p_1 = p_list[i]\n",
    "    p_set_1.append([p_1 for _ in range(3)])\n",
    "for i in range(13):\n",
    "    q_1 = q_list[i]\n",
    "    q_set_1.append([q_1 for _ in range(3)])\n",
    "\n",
    "# p_listから重複なく2つ選び、p_2を作成\n",
    "for i in range(5):\n",
    "    for j in range(i+1, 6):\n",
    "        p_set_2.append([p_list[i], p_list[j], p_list[j]])\n",
    "\n",
    "for i in range(12):\n",
    "    for j in range(i+1, 13):\n",
    "        q_set_2.append([q_list[i], q_list[j], q_list[j]])\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(i+1, 5):\n",
    "        for k in range(j+1, 6):\n",
    "            p_set_3.append([p_list[i], p_list[j], p_list[k]])\n",
    "\n",
    "for i in range(11):\n",
    "    for j in range(i+1, 12):\n",
    "        for k in range(j+1, 13):\n",
    "            q_set_3.append([q_list[i], q_list[j], q_list[k]])\n",
    "\n",
    "\n",
    "\n",
    "for i in p_set_1:\n",
    "    for j in q_set_1:\n",
    "        pairs_1_1.append((i, j))\n",
    "\n",
    "for i in p_set_1:\n",
    "    for j in q_set_2:\n",
    "        pairs_1_2.append((i, j))\n",
    "\n",
    "for i in p_set_1:\n",
    "    for j in q_set_3:\n",
    "        pairs_1_3.append((i, j))\n",
    "\n",
    "for i in p_set_2:\n",
    "    for j in q_set_1:\n",
    "        pairs_2_1.append((i, j))\n",
    "\n",
    "for i in p_set_2:\n",
    "    for j in q_set_2:\n",
    "        pairs_2_2.append((i, j))\n",
    "\n",
    "for i in p_set_2:\n",
    "    for j in q_set_3:\n",
    "        pairs_2_3.append((i, j))\n",
    "\n",
    "for i in p_set_3:\n",
    "    for j in q_set_1:\n",
    "        pairs_3_1.append((i, j))\n",
    "\n",
    "for i in p_set_3:\n",
    "    for j in q_set_2:\n",
    "        pairs_3_2.append((i, j))\n",
    "\n",
    "for i in p_set_3:\n",
    "    for j in q_set_3:\n",
    "        pairs_3_3.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_1 = pd.DataFrame(pairs_1_1, columns=['p', 'q'])\n",
    "df_1_2 = pd.DataFrame(pairs_1_2, columns=['p', 'q'])\n",
    "df_1_3 = pd.DataFrame(pairs_1_3, columns=['p', 'q'])\n",
    "df_2_1 = pd.DataFrame(pairs_2_1, columns=['p', 'q'])\n",
    "df_2_2 = pd.DataFrame(pairs_2_2, columns=['p', 'q'])\n",
    "df_2_3 = pd.DataFrame(pairs_2_3, columns=['p', 'q'])\n",
    "df_3_1 = pd.DataFrame(pairs_3_1, columns=['p', 'q'])\n",
    "df_3_2 = pd.DataFrame(pairs_3_2, columns=['p', 'q'])\n",
    "df_3_3 = pd.DataFrame(pairs_3_3, columns=['p', 'q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from old.utils import apply_features, convert_to_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   0%|          | 0/78 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 9 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_1_1 \u001b[38;5;241m=\u001b[39m \u001b[43mapply_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_1_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/meina-t/matching_with_dl/old/utils.py:178\u001b[0m, in \u001b[0;36mapply_features\u001b[0;34m(cfg, model, df, data)\u001b[0m\n\u001b[1;32m    175\u001b[0m q \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    177\u001b[0m model_output \u001b[38;5;241m=\u001b[39m model(p, q)\n\u001b[0;32m--> 178\u001b[0m model_efficiency_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_ev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m model_stability_loss \u001b[38;5;241m=\u001b[39m compute_sv(model_output, p, q)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    180\u001b[0m model_sp_loss \u001b[38;5;241m=\u001b[39m compute_spv(cfg, model, model_output, p, q)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 9 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "df_1_1 = apply_features(cfg, model, df_1_1, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
